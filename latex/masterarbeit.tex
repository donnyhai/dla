\documentclass[12pt,a4paper]{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[british,UKenglish,USenglish,american]{babel}

\usepackage[pdftex]{graphicx}
\usepackage{latexsym}
\usepackage{amsmath,amssymb,amsthm}
\allowdisplaybreaks
\usepackage{dsfont}
\usepackage{pifont}
\usepackage{nicefrac}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{lmodern}
\usepackage{enumitem}% http://ctan.org/pkg/enumerate
%\usepackage{enumerate}
\usepackage{bbm}

% Abstand obere Blattkante zur Kopfzeile ist 2.54cm - 15mm
\setlength{\topmargin}{-15mm}	   
                  
\numberwithin{equation}{section} 

\newcommand{\C}{\mathbb{C}} % komplexe
\newcommand{\R}{\mathbb{R}} % reelle
\newcommand{\Q}{\mathbb{Q}} % rationale
\newcommand{\Z}{\mathbb{Z}} % ganze
\newcommand{\N}{\mathbb{N}} % natuerliche
\newcommand{\PP}{\mathbb{P}} % Probability
\newcommand{\E}{\mathcal{E}} % big Epsilon
\newcommand{\K}{\mathcal{K}}

\numberwithin{equation}{section}

\theoremstyle{definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{algorithm}{Algorithm}
\newtheorem{prop}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{pro}{Proof}
\newtheorem{comment}{Comment}


\begin{document}
	\pagestyle{empty}

\begin{titlepage}

	\includegraphics[scale=0.45]{kit-logo.jpg} 
    \vspace*{2cm} 
\begin{center} \large 
    
   Masterthesis
    \vspace*{2cm}

    {\huge External DLA}\\
    \vspace*{2.5cm}

    Tillmann Tristan Bosch
    \vspace*{1.5cm}

    10. March 2020
    \vspace*{3.5cm}


    Supervisor: PD. Dr. Steffen Winter \\[1cm]
    Faculty of Mathematics\\[1cm]
	Karlsruhe Institute of Technology
\end{center}
\end{titlepage}

\newpage

\newpage
\phantom \\
\newpage

\tableofcontents %Inhaltsverzeichnis

 	\pagestyle{headings}

\setcounter{page}{1}

\newpage
\section{Einleitung}
External DLA beschreibt einen stochastischen Prozess, welcher zumindest in ähnlicher Form in natürlichen Prozessen beobachtbar ist. Er ähnelt zum Beispiel der fraktalen Gestalt eines sich kreisförmig ausbreitenden Risses einer Glasscheibe, oder eines Risses eines Kristallfluids wie in LCD Displays in alten Autoradios (siehe Fotos). Er kann auch in Schneeflocken oder in elektrostatischen Anhaftungen an Metallen beobachtet werden. Die Formalisierung solcher Prozesse ist sehr aktuell und die sehr konstruktive Definition erlaubten bisher nur mühsame Folgerungen über Struktur und Verhalten des Prozesses. Wir werden uns Modelle auf $\mathbb{Z}^2$, sowie auf anderen Graphen, darunter auch fraktale Graphen, anschauen, und außerdem versuchen, eine Approximation der bisherigen Definition zu finden, die grundsätzlich handlicher ist und auf einfachere Weise zu Erkenntnissen führt. Wir werden außerdem diese Arbeit mit einigen Python Simulationen begleiten. Der Code ist frei verfügbar auf Github. \\
\\

\includegraphics[scale=0.04]{display.jpg} 
\includegraphics[scale=0.091]{display2.jpg} 

\newpage


\section{Preliminaries} \label{prelim}

We prepare this script with the following preliminaries. \\
\\
\noindent $\boldsymbol{\mathit{General\ Definitions}}.\quad$ In this paper for practical purposes we will consider the natural numbers containing 0, so $\mathbb{N} := \{0, 1, 2, 3, \dots\}$. 
\\

\noindent $\boldsymbol{\mathit{Graphs}}.\quad$ We will be interested in the graph $(\mathbb{Z}^d, E)$ with its canonical graph structure, which is two vertices (or points) $x=(x_1,\dots,x_d),y=(y_1,\dots,y_d)\in \mathbb{Z}^d$ form an edge (e.q. $(x,y)\in E$) if and only if there exists exactly one $i\in \{1,\dots, d\}$ such that $|x_i - y_i| = 1$ and $x_j = y_j$ for all $j\neq i$. For a point $x\in \mathbb{Z}^d$ its set of $\mathit{neighbours}$ is defined as 
\begin{align*}
	N(x) := \{y\in \mathbb{Z}^d\ |\ (x,y)\in E\}
\end{align*}
and the canonical graph structure as defined above basically means that $N(x) = \{x+re_i\ |\ r\in \{-1,1\}\text{ and } i\in \{1,\dots, d\}\}$ where $e_i$ is the usual $i$-th standard basis vector of $\mathbb{Z}^d$, precisely $(e_i)_j=\delta_{ij}$ for all $i,j\in \{1, \dots , n \}$ where $\delta_{ij}=0$ if $i\neq j$ and $\delta_{ij}=1$ if $i=j$. For a set $A\subset \mathbb{Z}^d$ the $\mathit{outer\ boundary}\ \partial A$ of $A$ is defined as 
\begin{align*}
	\partial A := \{y\in \mathbb{Z}^d\setminus A\ |\ \exists x\in A:\ (x,y)\in E\}
\end{align*}
Instead of $(\mathbb{Z}^d, E)$ we will write $\mathbb{Z}^d$ from now on. 
\\

\noindent $\boldsymbol{\mathit{Probability\ Spaces}}.\quad$ Let $(\Omega,\mathcal{F}, \mathbb{P})$ be a probability space which we will base on in this paper. For our space of interest $\mathbb{Z}^d$ we will always use the discrete $\sigma$-Algebra which is the power set of $\mathbb{Z}^d$. If for $A\in \mathcal{F}$ we have $\mathbb{P}(A)=1$ we will say that $A$ holds $\mathbb{P}$-$a.s.$, or short $A$ holds $a.s.$ (almost sure).
\\

\noindent $\boldsymbol{\mathit{Random\ Walks}}.\quad$ First we define a $\mathit{Random\ Walk}$ on $\mathbb{Z}^d$ which we will use in this paper. A family $(S_n)_{n\in \mathbb{N}}$ of measurable functions $S_n: \Omega \to \mathbb{Z}^d$ is called a $\mathit{Random\ Walk\ on}\ \mathbb{Z}^d$ $\mathit{(starting\ at}\ x\in \mathbb{Z}^d)$ if and only if $S_0=x$ $a.s.$ and $\mathbb{P}(S_n\in N(y)\ |\ S_{n-1} = y) = 1$ for all $n \geq 1$ with 

\begin{align*}
	\mathbb{P}(S_n = y) = \frac{1}{|N(S_{n-1})|} = \frac{1}{2d}\quad \text{ for all }  y\in N(S_{n-1})\quad a.s., 
\end{align*}

note that $|N(y)| = 2d$ for all $y\in \mathbb{Z}^d$ since every point has two neighbours in every dimension. So a Random Walk can be understood as a particle starting from some point $x$ and moving randomly on the grid choosing its next step uniformly from its neighbour points. Furthermore define 

\begin{align*}
	\mathbb{P}_x(S_n\in A) := \mathbb{P}(S_n\in A|S_0=x)
\end{align*}

for any subset $A\subset G$. We define the $hitting\ time$ of A as 

\begin{align*}
	T(A) := \min \{n\geq 0\ |\ S_n\in A\},
\end{align*}

and $T(x):= T(\{x\})$ for one element sets and $x\in G$. The $heat\ kernel$ of the random walk $S_n$ is defined to be 

\begin{align*}
	p_n(x,y):=\mathbb{P}^n_x(S_n=y)
\end{align*}

and following the $\mathit{Green's\ function}$ as 

\begin{align*}
	G(x,y) := \sum_{n\geq 0} p_n(x,y).
\end{align*}

Similarily for a subset $A\subset G$ the $killed$ or $\mathit{stopped\ Green's\ function}$ is defined as

\begin{align*}
	G_A(x,y) := \sum_{n\geq 0} \mathbb{P}_x(S_n=y, T(A) > n).
\end{align*} 


\newpage
\section{Incremental Aggregate}
In this paper we will look at stochastic processes on the set of finite subsets of $\mathbb{Z}^d$, where we start with a one point set at $(0,0)$ and incrementally add a point on the outer boundary of the current cluster according to some distribution. What we get is a randomly, point-by-point growing connected cluster which here we will call $\mathit{Incremental\ Aggregate}$. Define 
\begin{align}
	\mathcal{P}_f := \{A\subset \mathbb{Z}^d\ |\ \text{A is finite}\}, 
\end{align}
the set of finite and connected subsets of $\mathbb{Z}^d$. Furthermore we will be interested in distributions on those sets, so for $A\in \mathcal{P}_f$ we define 
\begin{align}
	\mathcal{D}_A:= \{\mu: \mathbb{Z}^d\to [0,1]\ |\ \mu(y) = 0 \text{ for all } y\notin A\ \text{and}\ \sum_{y\in A} \mu(y) = 1 \}.
\end{align}
So every element in $\mathcal{D}_A$ naturally defines a distribution on the elements of $A$. Now we define $\mathit{Incremental\ Aggregate}$ as follows.  

\begin{definition}
	Let $\mu=(\mu_A)_{A\in \mathcal{P}_f}$ be a family of distributions with $\mu_A\in \mathcal{D}_A$ for all $A\in \mathcal{P}_f$. $\mathit{Incremental\ Aggregate\ (with\ distribution\ \mu)}$ is a stochastic process $(\mathcal{E}_n)_{n\in{\mathbb{N}_0}}$ which evolves as follows. The process starts with one point $\mathcal{E}_0 = \{(0,0)\}$ in the origin of $\mathbb{Z}^d$. Knowing the process $\mathcal{E}_n$ at time $n$, let $y_n$ be a random point in $\partial \mathcal{E}_n\in \mathcal{P}_f$ with distribution
	\begin{align}
		\mathbb{P}(y_n = y\ |\ \mathcal{E}_n) := \mu_{\partial \mathcal{E}_n}(y),\quad y\in \mathbb{Z}^d.
	\end{align}
	We then define $\mathcal{E}_{n+1} := \mathcal{E}_n \cup \{y_n\}$.
\end{definition} 

\begin{remark}
	
\end{remark}



\newpage

\newpage
\section{External DLA}

External DLA is a model of Incremental Aggregate as defined above using a very natural distribution, called the $\mathit{harmonic\ measure}$. 

\begin{definition} $\mathit{(Harmonic\ Measure)}$\\
	\\
	Remembering the definitions in \eqref{prelim}, especially the heat kernel $p_n(x,y):=\mathbb{P}_x(S_n=y)$ of a random walk, the $\mathit{hitting\ distribution}$ of elements in $A$ with $\mathit{hitting\ position}$ $S_{T(A)}$ is 
	\begin{align*}
	H_A(x,y) := p_{T(A)}(x,y),\quad y\in A, 
	\end{align*}
	and for the special case $x=o:=(0,0)$ we define
	\begin{align*}
	h_A(y) := H_A(o,y) = \mathbb{P}_o(S_{T(A)}=y),\quad y\in A.
	\end{align*}
	Thus, $h_A(y)$ is the probability of hitting $A$ for the first time at $y$ starting from $o$. $h_A$ is called the $\mathit{harmonic\ measure\ (from\ o)}$.
\end{definition}

\begin{lemma}
	harmonic measure := hearmonic measure from infinity. Why does this exist?
\end{lemma}

\begin{definition} $\mathit{(External\ Diffusion\ Limited\ Aggregate,\ External\ DLA)}$\\
	\\ Incremental Aggregate with the harmonic measure $h$ as its distribution we define here, and in literature is known as $\mathit{Exernal\ Diffusion\ Limited\ Aggregate}$, short $\mathit{External\ DLA}$.
\end{definition}

\begin{remark}
	contenu...
\end{remark}

\newpage
\section{Integral Geometry}

In the next section we want to define an approximation for DLA. To do this we will need some concepts and results from Integral Geometry which we will discuss and develop in this section. Reminder: A set $K\subset \mathbb{R}^d$ is called $\mathit{convex}$ if and only if for any two points $a,b\in K$ we have that $\{ta + (1-t)b \in \mathbb{R}^d\ |\ t\in [0,1]\}\subset K$. The set of convex and compact subsets of $\R^d$ we call $\K^d$. 

\subsection{Intrinsic Volumes}

A useful concept to measure intrinsic geometrical properties of Borel-sets $K\subset \R^d$ are $\mathit{intrinsic\ volumes}$. Define the $d$-th intrinsic volume of $K$ as $V_d(K):=\lambda_d(K)$. Furthermore define $S_{d-1}(K)$ to be the $\mathit{surface\ area}$ of $V_d(K)$, which is formally defined as the Hausdorff-measure of $\partial K$. If $\partial K$ is sufficiently regular (i.e. rectifiable, which is for example the case for all convex sets), then $S_{d-1}$ is equal to the $\mathit{outer\ Minkowski\ content}$, i.e.

\begin{flalign*}
	S_{d-1}(K) = M_{d-1}(K) := \lim_{\varepsilon \searrow 0} \frac{1}{\varepsilon} (V_d(K_{\oplus \varepsilon}) - V_d(K)),  \quad (Proof)
\end{flalign*}
where $K_{\oplus \varepsilon} = \{x\in \R^d\ |\ d(x,K)\leq \varepsilon\}$. It is easy to show, that $K_{\oplus \varepsilon} = K + \varepsilon B_d :=\{x+y\in \R^d\ |\ x\in K, y\in \varepsilon B_d\}$, where $B_d := \{x\in \R^d\ |\ d(0,x)\leq 1\}$. For the following theorem define 

\begin{flalign*}
	\kappa_d := V_d(B_d) \text{ for } d>0, \text{ and } \kappa_0:=1
\end{flalign*}

\noindent where we can calculate $V_d(B_d) = \frac{\pi ^{\frac{d}{2}}}{\Gamma(\frac{d}{2} + 1)}$ with the $\mathit{Gamma\ function}$ $\Gamma(x) := \int_0^\infty t^{x-1}e^{-t}dt,\ x>0$. 

\begin{theorem} $(\mathit{Steiner\ Formula})$
	For $K\in \K^d$ there exist uniquely determined numbers $V_0(K),\dots, V_d(K)\in \R$, such that for each $\varepsilon\geq 0$ 
	\begin{flalign} \label{steiner}
		V_d(K+\varepsilon B_d) = \sum_{j=0}^{d} \kappa_{d-j} \varepsilon^{d-j} V_j(K). 
	\end{flalign}
	\begin{proof}
		\cite{stoch1} Theorem 3.32
	\end{proof}
\end{theorem}

\begin{definition}
	$V_0(K),\dots, V_d(K)$ are called $\mathit{intrinsic\ volumes}$ of $K$. 
\end{definition}

\begin{remark}\label{Vjprop}
	\begin{enumerate}[label=(\roman*)]
		\item The coefficients $\kappa_{d-j}$ are chosen such that the $V_j$ become independent of the dimension of the underlying space. This means that $V_j$ will assign the same value for $K$ if $K$ is considered to be subset of $\R^d$ or $\R^{\tilde{d}}$ for  $d<\tilde{d}$, although the unit balls $B_d$ are different in those two spaces. This is why they are called intrinsic volumes. (REFERENCE)
		\item For $\varepsilon = 0$ the right side of \ref{steiner} reduces to $V_d(K)$ which shows a consistency of the notation. 
		\item With \ref{steiner} we get $S_{d-1}(K) = \lim_{\varepsilon \searrow 0} \frac{1}{\varepsilon} (V_d(K + \varepsilon B_d) - V_d(K) = \kappa_1 V_{d-1}(K)$, which will be a useful result. 
		\item It can be shown that $V_0(\emptyset)=\dots=V_d(\emptyset)=0$ and $V_0(K)=1$ if $K\neq \emptyset$. 
	\end{enumerate}
\end{remark}

\subsection{Random q-flats}

An interesting set in Integral Geometry is the set of $q$-dimensional affine subspaces in the $d$-dimensional real space, short $A(d,q)$ the set of $q$-flats in $\R^d$. 
Later we will be interested in choosing random lines (i.e. $2$-flats). For that we need a suitable $\sigma$-algebra and measure on $A(d,q)$ which we'll define now in this section. Let $G_d$ be the set of rigid motions (euclidean motions) in $\R^d$. For $r>0$ and $x\in \R^d$ define $B_d(r,x) := \{y\in \mathbb{R}^d\ |\ d(x,y) \leq r\}$ and $B_d:=B_d(1,0)$. 

\begin{definition}
	 For $r>0$ and $x\in \R^d$ define $A_d(r,x) := \{ F\in A(d,q)\ |\ F\cap B_d(r,x) \neq\emptyset \}$. Then the $\sigma$-algebra $\mathcal{A}(d,q)$ on $A(d,q)$ shall be defined by
	 \begin{flalign*}
	 	\mathcal{A}(d,q) := \sigma(\{ A_d(r,x)\ |\ r>0,x\in \R^d\}).
	 \end{flalign*} 
\end{definition}

\begin{theorem}
	On $A(d,q)$ there exists a unique $G_d$-invariant Radon measure $\mu_q$ such that
	\begin{flalign}
		\mu_q(A_d(1,0)) = \mu_q(\{F\in A(d,q)\ |\ F\cap B_d\neq \emptyset\}) = \kappa_{d-q}
	\end{flalign}
\end{theorem}
\begin{proof}
	\cite{stoch1} Theorem 4.26
\end{proof}

\begin{remark}
	For a convex set $K\in \K^d$ since $K$ is closed we can write $K=(\bigcup_{j=0}^\infty B_d(r_j, x_j))^C$ for some $r_j>0$ and $x_j\in \R^d$. Then we get
	\begin{flalign*}
		A_K :&= \{F\in A(d,q)\ |\ F\cap K\neq \emptyset\} 
		\\ &= \{F\in A(d,q)\ |\ F\cap (\bigcup_{j=0}^\infty B_d(r_j, x_j))^C \neq \emptyset\} 
		\\ &= \{F\in A(d,q)\ |\ F\cap \bigcap_{j=0}^\infty B_d(r_j, x_j)^C \neq \emptyset\} 
		\\ &= \{F\in A(d,q)\ |\ \bigcap_{j=0}^\infty F\cap B_d(r_j, x_j)^C\neq \emptyset\}
		\\ &= \{F\in A(d,q)\ |\ F\cap B_d(r_j, x_j)^C\neq \emptyset\text{ for all } j>0 \}
		\\ &\supset \{F\in A(d,q)\ |\ F\cap B_d(r_j, x_j) = \emptyset\text{ for all } j>0 \}
		\\ &= \bigcap_{j=0}^\infty \{F\in A(d,q)\ |\ F\cap B_d(r_j, x_j)= \emptyset\}
		\\ &= \bigcap_{j=0}^\infty A_d(r_j, x_j)^C
		\\ &= (\bigcup_{j=0}^\infty A_d(r_j, x_j))^C.
	\end{flalign*}
	$A_K\in \mathcal{A}(d,q)$ ?
\end{remark}

For convenience we define constants 
\begin{flalign*}
	c_s^r := \frac{r!\kappa_r}{s!\kappa_s}
\end{flalign*}
for $s,r\in \N_0$ and we set
\begin{flalign*}
	c^{r_1,\dots,r_k}_{s_1,\dots,s_k} := \prod_{j=1}^k c_{s_j}^{r_j}.
\end{flalign*}

\begin{theorem} $(\mathit{Crofton\ formula})$
	Let $K\in \K',k\in \{1,\dots,d-1\}$ and $j\in \{ 0,\dots,k\}$. Then
	\begin{flalign}
		\int_{A(d,k)} V_j(K\cap F) \mu_k(dF) = c^{k,d-k+j}_{j,d}V_{d-k+j}(K).
	\end{flalign} 
\end{theorem}

\begin{proof}
	\cite{stoch1} Theorem 4.27
\end{proof}

\begin{definition}
	Let $K_0\in \K^d$ with $V_d(K_0)>0$. Let $q\in \{0,\dots,d-1\}$. An $A(d,q)$-valued random element $X_q$ with distribution $\frac{\mu_q(\ \cdot\ \cap\ A_{K_0})}{\mu_q(A_{K_0})}$ is called an $\mathit{isotropic\ random\ q}$-$\mathit{flat}$ through $K_0$. 
\end{definition}

\begin{lemma} \label{K}
	Let $K,K_0\in \K^d$ with $K\subset K_0$ and $V_d(K_0)>0$. Let $q\in \{0,\dots,d-1\}$ and $X_q$ be an isotropic random $q$-flat through $K_0$. Then
\begin{flalign}
	\PP(X_q\cap K\neq \emptyset) = \frac{V_{d-q}(K)}{V_{d-q}(K_0)}. 
\end{flalign}
\end{lemma}
\begin{proof}
	We directly get
	\begin{flalign*}
		\PP(X_q\cap K \neq \emptyset) &= \PP(X_q\in A_K)
		= \frac{\mu_q(A_K\cap A_{K_0})}{\mu_q(A_{K_0})}
		\\ &= \frac{\mu_q(A_K)}{\mu_q(A_{K_0})}
		= \frac{\int_{A(d,q)} \mathbbm{1}\{F\cap K\neq \emptyset\} \mu_q(dF)}{\int_{A(d,q)} \mathbbm{1}\{F\cap K_0\neq \emptyset\} \mu_q(dF)}
		\\ &= \frac{\int_{A(d,q)} V_0(F\cap K) \mu_q(dF)}{\int_{A(d,q)} V_0(F\cap K_0) \mu_q(dF)}
		 \overset{Crofton}{=} \frac{c^{q,d-q}_{0,d}V_{d-q}(K)}{c^{q,d-q}_{0,d}V_{d-q}(K_0)}
		\\ &= \frac{V_{d-q}(K)}{V_{d-q}(K_0)}.
	\end{flalign*}
\end{proof}





\subsection{Constructions in the real plane}

From now on consider the case $d=2$ and $q=1$ which is looking at lines in the real plane. For some $K_0\in \K^2$ we will be interested in choosing a random line which intersects with $K_0$. We have looked at exactly this situation in Lemma (\ref{K}). We will look at some examples in this section, argue about why the measure $\mu_1$ is senseful to be used and what parametrisations on lines could be helpful to actually calculate realisations for random lines equivalently to $\mu_1$. In the next chapter we'll define an Incremental Aggregate where we'll use our insights here to realise random lines. Note that every line $X\in A:=A(2,1)$ has a form $X=X_{a,b}:=\{a+tb\in \R^2\ |\ t\in \R^2\}$ for some vectors $a,b\in \R^2$ with $b\neq (0,0)$. From now on for $r>0$ and $x\in \R^2$ define $B_r(x):= \{y\in R^2\ |\ d(x,y)\leq r\}$ and $B_r:=B_r(0)$. Let furthermore $X_1$ be an isotropic random $1$-flat through $K_0$. 

\begin{example}
	Let $0<r<R$, $K_0 := B_R$ and analogously $K:=B_r$. Note that $K,K_0\in \K^2$ and $K\subset K_0$. Then with Lemma (\ref{K}) and Remark (\ref{Vjprop}) (iii) we get
	\begin{flalign*}
		\PP(X_1\cap B_r) = \frac{V_1(B_r)}{V_1(B_R)} = \frac{S_1(B_r)}{S_1(B_R)} = \frac{2\pi r}{2\pi R} = \frac{r}{R}. 
	\end{flalign*}
\end{example}

\subsection{Easy attempt}

In this paper we will discuss the case $d=2$ and $q=1$, hence the set of lines in $\R^2$. 

\begin{definition}
	Let $K_0 \in \K^2$. Let $\gamma \sim \mathcal{U}([0,\pi))$ and for $\alpha \in [0,\pi)$ define $y_\alpha \sim \mathcal{U}(M_\alpha(K_0))$ where 
	\begin{align*}
		M_\alpha(K):= \begin{cases}
		\{h\in \mathbb{R}\ |\ L_{\tbinom{0}{h}, \tbinom{1}{0}} \cap K \neq \emptyset\},\quad \text{ if } \alpha = 0\\
		\{h\in \mathbb{R}\ |\ L_{\tbinom{h}{0}, \tbinom{cos(\alpha)}{sin(\alpha)}} \cap K \neq \emptyset\},\quad \text{ if } \alpha\in (0,\pi).
		\end{cases} 
	\end{align*}
	For $K\in \K^2$ define 

	\begin{flalign*}
		\nu_{K_0}(K) := \int_{[0,\pi)} \mathbb{P}_{y_\alpha}(M_\alpha(K\cap K_0)) \mathbb{P}_\gamma(d\alpha).
	\end{flalign*}
	Interpretation: $\nu_{K_0}(K)$ is the probability that a random line which intersects with $K_0$ also intersects with $K_0 \cap K$. \\
	Conjecture: $\nu_{K_0}(K) = \frac{\mu_1(K\cap K_0)}{\mu_1(K_0)}$ for $K,K_0\in \K^2$ ($\mu_1$  Gradenmaß).
\end{definition}

\begin{remark}
	Note that $	M_\alpha(K) \in\K^1$ for all $K\in \K^2$ and $\alpha\in [0,\pi)$ (Proof). Proof rotation symmetry.
\end{remark}

\begin{example}
	Let $0<r<R$ and $K_0 := B_R$ and analogously $K:=B_r$. Note that $K,K_0\in \K^2$ and $K\subset K_0$. Then by trigonometry we get 
	\begin{flalign*}
		M_\alpha(K_0) = \begin{cases}
			[-R,R],\quad \text{ if } \alpha=0,\\
			[-\frac{R}{sin(\alpha)}, \frac{R}{sin(\alpha)}],\quad \text{ if } \alpha\in (0,\pi)
		\end{cases}
	\end{flalign*} 
	and analogously $M_\alpha(K)$. Finally we get
	\begin{flalign*}
		\nu_{K_0}(K) &= \int_{[0,\pi)} \PP_{y_\alpha}(M_\alpha(K\cap \K_0)) \mathbb{P}_\gamma(d\alpha)\\
					&= \int_{[0,\pi)} \frac{\lambda(M_\alpha(K))}{\lambda(M_\alpha(K_0))} \frac{d\alpha}{\lambda([0,\pi))}\\
					&= \frac{1}{\pi} \int_{[0,\pi)} \frac{2r}{2R} d\alpha
					= \frac{1}{\pi} \frac{r}{R} \int_{[0,\pi)} 1 d\alpha
					= \frac{r}{R}
	\end{flalign*}
	This result makes sense considering the symmetries of the balls $B_r$ and $B_R$ and the relation of their diameters. 
\end{example}

\begin{example}
	Let $0<r\leq \frac{R}{\sqrt{2}}$, $K_0 := B_R$ as above and $K:= [-r,r]^2$. Note that $K,K_0\in \K^2$ and $K\subset K_0$. We get 
	\begin{flalign*}
		M_\alpha(K) = \begin{cases}
		[-r,r],\quad \text{ if } \alpha\in \{0,\frac{\pi}{2}\},\\
		[-r(1+\frac{1}{tan(\alpha)}),\ r(1+\frac{1}{tan(\alpha)})],\quad \text{ if } \alpha\in (0,\pi)\setminus \{\frac{\pi}{2}\}
		\end{cases}
	\end{flalign*}
	and finally 
	\begin{flalign*}
		\nu_{K_0}(K) &= \int_{[0,\pi)} \PP_{y_\alpha}(M_\alpha(K)) \mathbb{P}_\gamma(d\alpha)\\
		&= \frac{1}{\pi} \int_{(0,\pi)\setminus \{\frac{\pi}{2}\}} \frac{r}{R} (sin(\alpha) + cos(\alpha)) d\alpha\\
		&= \frac{r}{R\pi} [-cos(\alpha) + sin(\alpha)]^\pi_0 
		= \frac{r}{R\pi} (1 + 1) = \frac{2r}{R\pi}
	\end{flalign*}	
\end{example}

\begin{example}
	Let $K_0 := B_R$ and $K:=[-r,r]$ for some $0<r\leq R$. Note $K_0,K\in \K^2$ and $K\subset K_0$. Then 
	\begin{flalign*}
		M_\alpha(K) = \begin{cases}
			\{0\},\quad \alpha = 0,\\
			[-r,r],\quad \alpha\in (0,\pi).
		\end{cases}
	\end{flalign*}
	and finally
	\begin{flalign*}
		\nu_{K_0}(K) = \frac{1}{\pi} \int_{(0,\pi)} \frac{r}{R} sin(\alpha) d\alpha = \frac{2r}{R\pi}.
	\end{flalign*}
\end{example}

\begin{remark}
	Only fair if $K_0$ symmetric. 
\end{remark}

\newpage

\section{Line Hitting Aggregate}

In the following we will look at a process which is the approach of a simple approximation of external DLA on $\mathbb{Z}^2$. The idea is to let particles move on straight lines coming from infinity and add to the cluster when hitting it. Obviously in most cases particles cannot move completely straight on $\mathbb{Z}^2$. Therefore we will consider points in $\mathbb{Z}^2$ as the centers of unit squares and let the particles move on straight lines in the full plane $\mathbb{R}^2$. We consider a line hitting a point in $\mathbb{Z}^2$ if and only if it intersects with its unit square as defined in the following. 

\begin{definition}
	Define 
	\begin{align}
		\mathbb{R}^2_{sq} := \{[k - \frac{1}{2}, k + \frac{1}{2}] \times [l- \frac{1}{2}, l + \frac{1}{2}] \subset \mathbb{R}^2\ |\ k,l \in \mathbb{Z}\}, 
	\end{align} 
	note that $\mathbb{R}^2 = \bigcup_{s\in \mathbb{R}^2_{sq}} s$. The canonical function
	\begin{align}
	sq: \mathbb{Z}^2 \to \mathbb{R}^2_{sq},\quad (k,l)\to [k - \frac{1}{2}, k + \frac{1}{2}] \times [l- \frac{1}{2}, l + \frac{1}{2}]
	\end{align}
	is bijective and intuitively identifies points in $\mathbb{Z}^2$ with squares in $\mathbb{R}^2$, which is $p$ is the center of square $sq(p)$ for all $p\in \mathbb{Z}^2$. In the following when using a point $p\in \mathbb{Z}^2$ it will reference the point in $\mathbb{Z}^2$ or the corresponding square in $\mathbb{R}^2$ respecting the context. This bijection also naturally defines a graph structure on $\mathbb{R}^2_{sq}$, which is two squares $s_1, s_2\in \mathbb{R}^2_{sq}$ form an edge if and only if $sq^{-1}(s_1)$ and $sq^{-1}(s_2)$ form an edge in $\mathbb{Z}^2$. 
	\noindent For the following context we say a line $L$ $hits$ a point $p\in \mathbb{Z}^2$ if and only if $L\ \cap\ sq(p) \neq \emptyset$.
	
\end{definition}

BILD Linie durch squares "hitting"\\


\begin{definition}
	Geradenmaß $\mu_0$
\end{definition}


\begin{definition}
	Let $L=L_{a,b}\in \mathcal{L}$ be a line. For a finite set $A\in \mathcal{P}_f$ we define 
	
	\begin{align*}
		L_{A} := \{ p\in A\ |\ L \text{ hits } p\}
	\end{align*}
	
	which is the subset of points in $A$ are hit by the line $L$ hits. For the following we suppose $L_A \neq \emptyset$. We want to define a total ordered relation $<_{line}$ on $L_A$. We choose two points $(x_1,x_2),(y_1,y_2)\in L_A$ and devide the definition of a relation into four cases, which are the line going from left-bottom to right-top, left-top to right-bottom, parallel to the $x$-axis and parallel to the $y$-axis. Write $b=(b_1,b_2)$.  \\
	\\
	$\mathit{Case\ 1:}\quad L\ \text{ is parallel to the x-axis}\quad \Leftrightarrow\quad b_2=0$
	\begin{align*}
	(x_1, x_2) <_{line} (y_1, y_2) \quad :\Leftrightarrow \quad x_1 < y_1
	\end{align*}\\
	$\mathit{Case\ 2:}\quad L\ \text{ is parallel to the y-axis}\quad \Leftrightarrow\quad b_1=0$
	\begin{align*}
	(x_1, x_2) <_{line} (y_1, y_2) \quad :\Leftrightarrow \quad x_2 < y_2
	\end{align*}\\
	$\mathit{Case\ 3:}\quad L\ \text{ is going from left-bottom to right-top}\quad \Leftrightarrow\quad b_1b_2>0$
	\begin{align*}
	(x_1, x_2) <_{line} (y_1, y_2) \quad :\Leftrightarrow \quad
		\begin{cases}
			x_1 < y_1, & \text{ if } x_1 \neq y_1, \\
			x_2 < y_2, & \text{ if } x_1 = y_1.
		\end{cases}
	\end{align*}\\
	$\mathit{Case\ 4:}\quad L\ \text{ is going from left-top to right-bottom}\quad \Leftrightarrow\quad b_1b_2<0$
	\begin{align*}
	(x_1, x_2) <_{line} (y_1, y_2) \quad :\Leftrightarrow \quad
	\begin{cases}
	x_1 < y_1, & \text{ if } x_1 \neq y_1, \\
	x_2 > y_2, & \text{ if } x_1 = y_1.
	\end{cases}
	\end{align*}\\
	It is easy to see that this well-defines a relation on $L_A$. In the following we will quickly proove that this relation is totally ordered. 
\end{definition}

\begin{lemma}
For a line $L=L_{a,b}\in \mathcal{L}$ and $A\in \mathcal{P}_f$ with $L_A\neq \emptyset$ the relation $<_{line}$ on $L_A$ is totally ordered. 
	\begin{proof}
		We will only proove the case where $L$ is going from left-bottom to right-top, which is $\mathit{Case\ 3}$ of the definition. In this case we have $b_1b_2>0$. Note, that the proof for $\mathit{Case\ 4}$ will work very similair. And in the case of $L$ being parallel to one of the axes ($\mathit{Case\ 1\ or\ 2}$), all properties for a totally ordered relation follow directly from the totally ordered relation $<$ on $\mathbb{R}$. So let $b_1b_2>0$. \\
		\\
		$\mathit{Antisymmetry:}$ For antisymmetry let $(x_1, x_2) <_{line} (y_1, y_2)$ and $(y_1, y_2) <_{line} (x_1, x_2)$. Suppose $x_1\neq y_1$, then $x_1 < y_1$ and $y_1 < x_1$, therefore $x_1 = y_1$ by antisymmetry of the standard order $<$ in $\mathbb{R}$, a contradiction, hence $x_1 = y_1$. But then we have $x_2 < y_2$ and $y_2 < x_2$ and therefore also $x_2 = y_2$. \\
		\\
		$\mathit{Transitivity:}$ For transitivity let $(x_1,x_2) <_{line} (y_1,y_2)$ and $(y_1,y_2) <_{line} (z_1,z_2)$. We find four cases. In case $x_1 \neq y_1$ and $y_1 \neq z_1$ we get $x_1 < z_1$ by transitivity of $<$, hence $(x_1,x_2) <_{line} (z_1,z_2)$. In case $x_1\neq y_1$ and $y_1 = z_1$ we get $x_1 < y_1 = z_1$, therefore $(x_1,x_2) <_{line} (z_1,z_2)$. In case $x_1 = y_1$ and $y_1 \neq z_1$ we get $x_1 = y_1 < z_1$, similair as the last case. In the last case $x_1 = y_1 = z_1$ we get $x_2 < y_2$ and $y_2 < z_2$ and again by transitivity of $<$ we get $x_2 < z_2$, hence $(x_1,x_2) <_{line} (z_1,z_2)$ again. \\
		\\
		$\mathit{Connexity:}$ Connexity is given since for any two points $(x_1,x_2),(y_1,y_2)\in L_A$ we have either $x_1 \neq y_1$ or $x_1 = y_1$ and therefore either $(x_1,x_2)<_{line}(y_1,y_2)$ or $(y_1,y_2)<_{line}(x_1,x_2)$.
	 
	\end{proof}
\end{lemma}

\begin{remark}
	The relation $<_{line}$ on $L_A$ basically orders the hitpoints of a line $L$ with a finite set $A$ from left to right (or bottom to top in case of a line parallel to the $y$-axis). This order allows us to identify the outest hitting points of $A$ by $L$. This means when moving on a line $L$ facing $A$ this order allows us to know where in $A$ the line $L$ hits first when ,,entering`` $A$ and where it hits last when ,,leaving`` $A$ which will be the two points $min_{<_{line}}L_A$ and $max_{<_{line}}L_A$ (or the other way around). 
\end{remark}


\begin{definition} $\mathit{Random\ Line\ Hitting\ Distribution}$\\
	\indent Choose $A\in \mathcal{P}_f$. We define a distribution $\mu_A$ on $\mathbb{Z}^2$ as in the following. 
	Let $L=L_{a,b}$ be a random line according to the line measure $\mu_0$ with the condition that $L$ hits $A$. Then define $\mu_A$ with distribution $\mu_A \sim U(\{min_{<_{line}}L_A, max_{<_{line}}L_A\})$, which chooses uniformly an element out of $\{min_{<_{line}}L_A, max_{<_{line}}L_A\}$. We call this distribution the $\mathit{Random\ Line\ Hitting\ Distribution\ (of\ A)}$.
\end{definition}

\begin{definition} $\mathit{Line\ Hitting\ Aggregate}$\\
	\indent Incremental Aggregate with the Random Line Hitting Distribution as its distribution we will call here $\mathit{Line\ Hitting\ Aggregate}$, short $\mathit{LHA}$. 
\end{definition}

\section{Questions}
$\mathcal{K}'=?$

\newpage

\begin{thebibliography}{biblio}
\thispagestyle{empty}

\bibitem{Henze Skript}
N. Henze.
\emph{Maß und Wahrscheinlichkeitstheorie (Stochastik II)}.
Karlsruher Institut für Technologie, Karlsruhe, 2010

\bibitem{stoch1}
Daniel Hug, Günter Last, Steffen Winter.
\emph{Stochastic Geometry, 	Lecture Notes (summer term 2020)}.
Institute of Technologie, Karlsruhe



\end{thebibliography}

\newpage
  
\thispagestyle{empty}

\vspace*{8cm}


\section*{Erklärung}

Hiermit versichere ich, dass ich diese Arbeit selbständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt, die wörtlich oder inhaltlich übernommenen Stellen als solche kenntlich gemacht und die Satzung des Karlsruher Instituts für Technologie zur Sicherung guter wissenschaftlicher Praxis in der jeweils gültigen Fassung beachtet habe. \\[2ex] 

\noindent
Karlsruhe, den 10. März 2020\\[5ex] 

\end{document}

